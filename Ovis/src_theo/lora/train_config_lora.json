{
    "model_path": "AIDC-AI/Ovis2.5-9B",
    "visual_vocab_size": 65536,
    
    "lora_r": 128,
    "lora_alpha": 256,
    "lora_dropout": 0.05,
    "lora_target_modules": "q_proj,k_proj,v_proj,o_proj,gate_proj,up_proj,down_proj",
    "apply_lora_to_vision": true,
    
    "data_name": "test_dataset",
    "data_type": "conversation",
    "data_path": "./Ovis/src_theo/sample_data/train_data.json",
    "eval_data_path": null,
    "image_folder": "./Ovis/src_theo/sample_data/",
    "single_image_min_pixels": 200704,
    "single_image_max_pixels": 3211264,
    "multiple_image_min_pixels": 200704,
    "multiple_image_max_pixels": 802816,
    "video_min_pixels": 200704,
    "video_max_pixels": 802816,
    "min_frames": 10,
    "max_frames": 10,
    
    "output_dir": "./Ovis/checkpoints/ovis25_lora_finetune",
    "overwrite_output_dir": true,
    "do_train": true,
    "do_eval": false,
    "num_train_epochs": 3,
    "per_device_train_batch_size": 2,
    "gradient_accumulation_steps": 8,
    "eval_strategy": "no",
    "save_strategy": "steps",
    "learning_rate": 1e-4,
    "max_grad_norm": 1.0,
    "weight_decay": 0.0,
    "warmup_steps": 100,
    "warmup_ratio": 0.1,
    "lr_scheduler_type": "cosine",
    "logging_steps": 5,
    "save_steps": 0.5,
    "save_total_limit": 3,

    "tf32": true,
    "fp16": false,
    "bf16": true,
    "torch_dtype": "bfloat16",
    
    "dataloader_pin_memory": false,
    "dataloader_num_workers": 4,
    "dataloader_drop_last": true,
    "dataloader_persistent_workers": true,
    "gradient_checkpointing": false,
    "deepspeed": null,
    
    "ovis_pretrained_path": "AIDC-AI/Ovis2.5-9B",
    "stage": 3,
    "multimodal_max_length": 8192,
    "text_max_length": 6000,
    "attn_implementation": "flash_attention_2",
    
    "seed": 42,
    "data_seed": 42,
    "remove_unused_columns": false,
    "report_to": "none",
    
    "packing": false,
    "max_seq_length": 8192,
    "dataset_text_field": null,
    "formatting_func": null
}