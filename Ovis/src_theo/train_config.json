{
    "model_path": "AIDC-AI/Ovis2.5-9B",
    "visual_vocab_size": 65536,
    
    "data_name": "test_dataset",
    "data_type": "conversation",
    "data_path": "./Ovis/src_theo/sample_data/train_data.json",
    "image_folder": "./Ovis/src_theo/sample_data/",
    "single_image_min_pixels": 200704,
    "single_image_max_pixels": 3211264,
    "multiple_image_min_pixels": 200704,
    "multiple_image_max_pixels": 802816,
    "video_min_pixels": 200704,
    "video_max_pixels": 802816,
    
    "output_dir": "./checkpoints/ovis25_finetune",
    "overwrite_output_dir": true,
    "do_train": true,
    "do_eval": false,
    
    "num_train_epochs": 3,
    "per_device_train_batch_size": 1,
    "gradient_accumulation_steps": 8,
    "learning_rate": 2e-5,
    "weight_decay": 0.01,
    "warmup_steps": 100,
    
    "logging_steps": 10,
    "save_steps": 500,
    "save_total_limit": 3,
    
    "bf16": true,
    "dataloader_pin_memory": false,
    "dataloader_num_workers": 0,
    
    "gradient_checkpointing": true,
    "deepspeed": null,
    
    "train_modules": "all",
    "freeze_vision_tower": false,
    "freeze_llm": false,
    
    "ovis_pretrained_path": "AIDC-AI/Ovis2.5-9B",
    "LLM_MODEL": "Qwen/Qwen3-8B",
    "VIT_MODEL": "google/siglip2-so400m-patch16-512",
    "stage": 3,
    "multimodal_max_length": 8192,
    "text_max_length": 4096,
    
    "seed": 42,
    "data_seed": 42,
    "remove_unused_columns": false,
    "report_to": [],
    
    "packing": false
  }